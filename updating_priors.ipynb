{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T14:21:36.612388Z",
     "start_time": "2024-06-18T14:21:29.639073Z"
    }
   },
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "\n",
    "import arviz as az\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pymc as pm\n",
    "# import theano.tensor as tt\n",
    "\n",
    "from pymc import Model, Normal, Slice, sample\n",
    "from pymc import Interpolated\n",
    "from scipy import stats\n",
    "# from theano import as_op\n",
    "\n",
    "# plt.style.use(\"seaborn-darkgrid\")\n",
    "print(f\"Running on PyMC v{pm.__version__}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on PyMC3 v5.10.3\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Initialize random number generator\n",
    "np.random.seed(93457)\n",
    "\n",
    "# True parameter values\n",
    "alpha_true = 5\n",
    "beta0_true = 7\n",
    "beta1_true = 13\n",
    "\n",
    "# Size of dataset\n",
    "size = 100\n",
    "\n",
    "# Predictor variable\n",
    "X1 = np.random.randn(size)\n",
    "X2 = np.random.randn(size) * 0.2\n",
    "\n",
    "# Simulate outcome variable\n",
    "Y = alpha_true + beta0_true * X1 + beta1_true * X2 + np.random.randn(size)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# from itertools import chain\n",
    "\n",
    "\n",
    "basic_model = Model()\n",
    "\n",
    "with basic_model:\n",
    "    # Priors for unknown model parameters\n",
    "    alpha = Normal(\"alpha\", mu=0, sigma=1)\n",
    "    beta0 = Normal(\"beta0\", mu=12, sigma=1)\n",
    "    beta1 = Normal(\"beta1\", mu=18, sigma=1)\n",
    "\n",
    "    # Expected value of outcome\n",
    "    mu = alpha + beta0 * X1 + beta1 * X2\n",
    "\n",
    "    # Likelihood (sampling distribution) of observations\n",
    "    Y_obs = Normal(\"Y_obs\", mu=mu, sigma=1, observed=Y)\n",
    "\n",
    "    # draw 1000 posterior samples\n",
    "    trace = sample(1000, chains=4)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def from_posterior(param, samples):\n",
    "    smin, smax = np.min(samples), np.max(samples)\n",
    "    width = smax - smin\n",
    "    x = np.linspace(smin, smax, 100)\n",
    "    y = stats.gaussian_kde(samples)(x)\n",
    "\n",
    "    # what was never sampled should have a small probability but not 0,\n",
    "    # so we'll extend the domain and use linear approximation of density on it\n",
    "    x = np.concatenate([[x[0] - 3 * width], x, [x[-1] + 3 * width]])\n",
    "    y = np.concatenate([[0], y, [0]])\n",
    "    return Interpolated(param, x, y)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "traces = [trace]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "for _ in range(10):\n",
    "    # generate more data\n",
    "    X1 = np.random.randn(size)\n",
    "    X2 = np.random.randn(size) * 0.2\n",
    "    Y = alpha_true + beta0_true * X1 + beta1_true * X2 + np.random.randn(size)\n",
    "\n",
    "    model = Model()\n",
    "    with model:\n",
    "        # Priors are posteriors from previous iteration\n",
    "        alpha = from_posterior(\"alpha\", trace.posterior[\"alpha\"][0, :])\n",
    "        beta0 = from_posterior(\"beta0\", trace.posterior[\"beta0\"][0, :])\n",
    "        beta1 = from_posterior(\"beta1\", trace.posterior[\"beta1\"][0, :])\n",
    "\n",
    "        # Expected value of outcome\n",
    "        mu = alpha + beta0 * X1 + beta1 * X2\n",
    "\n",
    "        # Likelihood (sampling distribution) of observations\n",
    "        Y_obs = Normal(\"Y_obs\", mu=mu, sigma=1, observed=Y)\n",
    "\n",
    "        # draw 10000 posterior samples\n",
    "        trace = sample(1000, chains=1)\n",
    "        traces.append(trace)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"Posterior distributions after \" + str(len(traces)) + \" iterations.\")\n",
    "cmap = mpl.cm.autumn\n",
    "for param in [\"alpha\", \"beta0\", \"beta1\"]:\n",
    "    plt.figure(figsize=(8, 2))\n",
    "    for update_i, trace in enumerate(traces):\n",
    "        samples = trace.posterior[param][0, :]\n",
    "        smin, smax = np.min(samples), np.max(samples)\n",
    "        x = np.linspace(smin, smax, 100)\n",
    "        y = stats.gaussian_kde(samples)(x)\n",
    "        plt.plot(x, y, color=cmap(1 - update_i / len(traces)))\n",
    "    plt.axvline({\"alpha\": alpha_true, \"beta0\": beta0_true, \"beta1\": beta1_true}[param], c=\"k\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(param)\n",
    "\n",
    "plt.tight_layout();"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "trace.poste"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
